---
title: "CH08P21 Cluster Analysis"
author: "crl"
date: "January 11, 2018"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
```

# QCI Six Sigma Primer
## Cluster Analysis

## Load Packages
```{r load packages, echo = TRUE}
library(tidyverse)
```

## Read about Cluster Analysis

[Example here](https://www.statmethods.net/advstats/cluster.html)

[Read more](https://rstudio-pubs-static.s3.amazonaws.com/33876_1d7794d9a86647ca90c4f182df93f0e8.html)

[Presentation](https://drive.google.com/open?id=1xf-QAsBf-Z6s8w93aQBQSCWcbHHs62fX)



## Get Data
We can load data from a csv file, such as:
```{r load data, echo = TRUE}
(cdat = read.csv('data/ch08p19-discriminant-analysis.csv', header = TRUE, stringsAsFactors = FALSE))
```

Scale the numeric columns of the data
```{r scale data}
(cdat_scaled <- scale(cdat[sapply(cdat, is.numeric)])) # standardize variables
```



## Cluster Analysis

### One method for finding the number of clusters

```{r number of clusters}
nrow_dat <- nrow(cdat_scaled)
wss <- (nrow_dat - 1)*sum(apply(cdat_scaled, 2, var))

for (i in 2:(nrow_dat-1)){
  wss[i] <- sum(kmeans(cdat_scaled, centers = i)$withinss)
}

plot(1:(nrow_dat-1), wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")
```


### Clustering based on hierarchical clustering

distance options:
    "euclidean", "maximum", "manhattan", "canberra", "binary" or "minkowski"

hclust options:
    "ward.D", "ward.D2", "single", "complete", "average" (= UPGMA) 
    "mcquitty" (= WPGMA), "median" (= WPGMC) or "centroid"

```{r fit cluster, echo = TRUE}
# Ward Hierarchical Clustering
d <- dist(cdat_scaled, method = "euclidean") # distance matrix
fit_cl <- hclust(d, method = "centroid") 
```

### Plot clusters

```{r plot cluster}
plot(fit_cl) # display dendogram
groups <- cutree(fit_cl, k=2) # cut tree into 5 clusters
# draw dendogram with red borders around the 5 clusters 
rect.hclust(fit_cl, k=2, border="red")
```


## End
